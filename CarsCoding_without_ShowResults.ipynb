{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b612fc52",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69add9de",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil, glob, random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db285000",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62db1b8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv('./data/car_imgs_4000.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c25fe9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd28a1",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['perspective_score_hood']= round(df.perspective_score_hood, 2)\n",
    "df['perspective_score_backdoor_left']= round(df.perspective_score_backdoor_left, 2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c4d22f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157260e6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show the class imbalance in the data\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, figsize=(30,10))\n",
    "sns.countplot((df.perspective_score_hood.values * 100).astype(int), ax= ax1)\n",
    "plt.ylabel('hood_count');\n",
    "\n",
    "sns.countplot((df.perspective_score_backdoor_left.values * 100).astype(int), ax= ax2)\n",
    "plt.ylabel('door_count');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d71f8f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#df.perspective_score_backdoor_left.value_counts(normalize=False).sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7f7a7c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show 5 samples of the croped images\n",
    "src_dir= 'data/croped_imgs2/'\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    f= os.listdir(src_dir)[i]\n",
    "    img_path= os.path.join(src_dir, f)\n",
    "    #print(img_path)\n",
    "    img= image.load_img(img_path)\n",
    "    img= img.resize((90,90))\n",
    "    img= image.img_to_array(img)/255.\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis('off')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71717453",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show the classes with majority sample\n",
    "\n",
    "#np.where(df.perspective_score_hood.value_counts(normalize=True) > 0.050)\n",
    "#df[df.groupby('perspective_score_hood')['perspective_score_hood'].transform('size') > 0.50]\n",
    "count= df.perspective_score_hood.value_counts(normalize=True)\n",
    "df[df.perspective_score_hood.map(count >0.06)]['perspective_score_hood'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30478bf8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mergeing classes into 5 to have enough samples per class for training\n",
    "#classes ranges for modelling:\n",
    "# 0 = 0.0 - 0.20\n",
    "# 1 = 0.21 - 0.40\n",
    "# 2 = 0.41 - 0.60\n",
    "# 3 = 0.61 - 0.80\n",
    "# 4 = 0.81 - 0.93\n",
    "\n",
    "src_dir= './data/croped_imgs/'\n",
    "save_dir= './data/merged_hood/'\n",
    "class_0 = []\n",
    "#missing= [i for i in set(df.perspective_score_hood.values) if str(i) not in os.listdir(save_dir)]\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "for image in os.listdir(src_dir):\n",
    "    for i in np.arange(0.91,0.92,0.01):\n",
    "        i = round(i,2)\n",
    "        for v, f in zip(df.perspective_score_hood.values, df.filename):\n",
    "            if v == i and f in os.path.join(src_dir, image):\n",
    "                #print(v)\n",
    "                class_0.append([f, v])\n",
    "                sub_dir= os.path.join(save_dir, str(5))\n",
    "                os.makedirs(sub_dir, exist_ok= True)\n",
    "                #print('*'*50)\n",
    "                shutil.move(os.path.join(src_dir, f), os.path.join(sub_dir, f))\n",
    "                print(f'moved from {os.path.join(src_dir, f)} to { os.path.join(sub_dir, f)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e1d9fb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# count the images in a subfolder\n",
    "count = 0\n",
    "save_dir= 'data/split_hood2/test'\n",
    "# Iterate directory\n",
    "for path in os.listdir(save_dir):\n",
    "    for file in os.listdir(os.path.join(save_dir,path)):\n",
    "    # check if current path is a file\n",
    "        if os.path.isfile(os.path.join(save_dir, path, file)):\n",
    "            count += 1\n",
    "print('File count:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884bfbb5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# count images in each subfolder\n",
    "for dir,subdir,files in os.walk('data/merged_hood'):\n",
    "    print(np.sort([dir, str(len(files))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d07bf2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sepecify images in each class up to max_number and remove the rest to a folder for the sake of class balancing\n",
    "\n",
    "# Set the path to the directory containing labeled subdirectories\n",
    "base_dir = 'data/merged_hood'\n",
    "\n",
    "# Specify the desired subdirectory labels\n",
    "desired_labels = ['0.00', '0.90', '0.91']\n",
    "\n",
    "# Set the destination directory\n",
    "dest_dir = 'data/residue_hood/'\n",
    "if not os.path.exists(dest_dir):\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "# Specify the maximum allowed count\n",
    "max_count = 400\n",
    "\n",
    "# Loop through each subdirectory, count images, and move if count exceeds max_count\n",
    "for subdir_label in os.listdir(base_dir):\n",
    "    if subdir_label == str(4):\n",
    "        subdir_path = os.path.join(base_dir, subdir_label)\n",
    "        # Get a list of files in the subdirectory\n",
    "        files = [file for file in os.listdir(subdir_path) if os.path.isfile(os.path.join(subdir_path, file))]\n",
    "        \n",
    "        # Count the number of images in the subdirectory\n",
    "        count = len(files)\n",
    "        \n",
    "        # Print or process the count\n",
    "        print(f\"Number of images in {subdir_label}: {count}\")\n",
    "        \n",
    "        # Move images if count exceeds max_count\n",
    "        if count > max_count:\n",
    "            # Select the first (count - max_count) images to move\n",
    "            images_to_move = files[:count - max_count]\n",
    "            \n",
    "            # Move selected images to the destination directory\n",
    "            for image in images_to_move:\n",
    "                source_path = os.path.join(subdir_path, image)\n",
    "                sub_dest_dir = os.path.join(dest_dir, subdir_label)\n",
    "                os.makedirs(sub_dest_dir, exist_ok= True)\n",
    "                shutil.move(source_path, os.path.join(sub_dest_dir, str(image)))\n",
    "                print(f\"Moved {image} to {dest_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff8ec46",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(os.listdir('data/merged_hood/4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd28dbd7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Crop Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfb321c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9644dce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# crop images with a pretrained Yolo-v8 model\n",
    "# We trained Yolo with 500 samples and validated and tested with 500 each. We ran the model for 50 epochs on TPU\n",
    "# Colab – the loss in the detection box was roughly 1.6 – we could have trained the model for 100 epochs with\n",
    "# more samples (e.g 1000) for better croping accuracy\n",
    "\n",
    "custom_model = YOLO('best.pt')\n",
    "base_dir= 'data/original_data/imgs/'\n",
    "\n",
    "for image in os.listdir(base_dir):\n",
    "    img_path= os.path.join(base_dir, image)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    img= cv2.resize(img, (160, 160), interpolation= cv2.INTER_AREA)\n",
    "    results = custom_model(img)\n",
    "    for n, box in enumerate(results[0].boxes.xywhn):\n",
    "        h, w = img.shape[:2]\n",
    "        x1, y1, x2, y2 = box.numpy()\n",
    "        x_center, y_center = int(float(x1) * w), int(float(y1) * h)\n",
    "        box_width, box_height = int(float(x2) * w), int(float(y2) * h)\n",
    "\n",
    "        x_min = int(x_center - (box_width / 2))\n",
    "        y_min = int(y_center - (box_height / 2))\n",
    "        crop_img= img[y_min:y_min+int(box_height), x_min:x_min+int(box_width)]\n",
    "\n",
    "        save_path= f'data/croped_imgs/'\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path, exist_ok= True)\n",
    "        cv2.imwrite(save_path + f\"{image}\", crop_img)\n",
    "        print(f'crop image {img_path} to {os.path.join(save_path,image)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef61d8a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(os.listdir(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b9fd79",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Split Data for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee541f77",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import vgg16, resnet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813668f7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_hood= 'data/merged_hood/'\n",
    "#data_door= 'data/balanced_door_croped/'\n",
    "\n",
    "split_hood= 'data/split_hood2/'\n",
    "#split_door= 'data/split_door/'\n",
    "\n",
    "splitfolders.ratio(data_hood, split_hood, seed=1337, ratio= (0.70, 0.25, 0.05))\n",
    "#splitfolders.ratio(data_door, split_door, seed=1337, ratio= (0.70, 0.25, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726bc93f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create features and corresponding labels\n",
    "\n",
    "def create_dataset(img_folder):\n",
    "    features=[]\n",
    "    labels=[]\n",
    "    IMG_WIDTH=160\n",
    "    IMG_HEIGHT=160\n",
    "    for label in os.listdir(img_folder):\n",
    "        image_path= os.path.join(img_folder,label)\n",
    "        for img in os.listdir(image_path):\n",
    "            image= cv2.imread(os.path.join(image_path, img), cv2.COLOR_BGR2RGB)\n",
    "            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH))\n",
    "            features.append(image)\n",
    "            labels.append(label)\n",
    "    features, labels = shuffle(features, labels)\n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf966a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_hood, y_train_hood= create_dataset(split_hood + 'train')\n",
    "#X_train_door, y_train_door= create_dataset(split_door + 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ed103",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_val_hood, y_val_hood= create_dataset(split_hood + 'val')\n",
    "#X_val_door, y_val_door= create_dataset(split_door + 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d9b37",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_classes_hood= len(np.unique(y_train_hood, return_counts=False))\n",
    "#num_classes_door= len(np.unique(y_train_door, return_counts=False))\n",
    "print(num_classes_hood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d40a8a4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# manual split of data (or by using splitfolders library as above)\n",
    "\n",
    "# train_size_hood= int(len(features_hood) * 0.80)\n",
    "\n",
    "# X_train_hood= features_hood[:train_size_hood]\n",
    "# y_train_hood= labels_hood[:train_size_hood]\n",
    "# X_val_hood= features_hood[train_size_hood:]\n",
    "# y_val_hood= labels_hood[train_size_hood:]\n",
    "\n",
    "# train_size_door= int(len(features_door) * 0.80)\n",
    "\n",
    "# X_train_door= features_door[:train_size_door]\n",
    "# y_train_door= labels_door[:train_size_door]\n",
    "# X_val_door= features_door[train_size_door:]\n",
    "# y_val_door= labels_door[train_size_door:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3486058",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check the shape of features and labels\n",
    "X_train_hood.shape, y_train_hood.shape, X_val_hood.shape, y_val_hood.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c9b851",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#X_train_door.shape, y_train_door.shape, X_val_door.shape, y_val_door.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a73ea4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# categorical encoding for integer labels\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_hood= to_categorical(y_train_hood, num_classes= num_classes_hood)\n",
    "y_val_hood= to_categorical(y_val_hood, num_classes= num_classes_hood)\n",
    "\n",
    "#y_train_door= to_categorical(y_train_door, num_classes= num_classes_door)\n",
    "#y_val_door= to_categorical(y_val_door, num_classes= num_classes_door)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf83163a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# For base Modelling or implement it in the model architecture as Rescaling layer\n",
    "# X_train_hood= X_train_hood/255.\n",
    "# X_val_hood= X_val_hood/255.\n",
    "\n",
    "# X_train_door= X_train_door/255.\n",
    "# X_val_door= X_val_door/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64911787",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# For Transfer Learning Modelling\n",
    "X_train_hood= resnet50.preprocess_input(X_train_hood).astype(float)\n",
    "X_val_hood= resnet50.preprocess_input(X_val_hood).astype(float)\n",
    "\n",
    "#X_train_door= vgg16.preprocess_input(X_train_door).astype(float)\n",
    "#X_val_door= vgg16.preprocess_input(X_val_door).astype(float)\n",
    "\n",
    "y_train_hood= y_train_hood.astype(float)\n",
    "y_val_hood= y_val_hood.astype(float)\n",
    "\n",
    "#y_train_door= y_train_door.astype(float)\n",
    "#y_val_door= y_val_door.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccaa504",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_door[0,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d44a6e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    '''instanciate and return the CNN architecture with augmenting and rescaling layers'''\n",
    "    \n",
    "    augmentation = Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomZoom(0.1),\n",
    "        layers.RandomTranslation(0.2, 0.2),\n",
    "        layers.RandomRotation(0.1)\n",
    "    ])\n",
    "    \n",
    "    model= Sequential([\n",
    "        layers.Input(X_train_hood[0,:,:].shape),\n",
    "        layers.Rescaling(scale= 1./255.),\n",
    "        augmentation,\n",
    "        layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPool2D(pool_size= (2,2), padding= 'same'),\n",
    "        \n",
    "        layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPool2D(pool_size= (2,2), padding= 'same'),\n",
    "\n",
    "        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPool2D(pool_size= (2,2), padding= 'same'),\n",
    "        \n",
    "        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPool2D(pool_size= (2,2), padding= 'same'),\n",
    "        \n",
    "        layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPool2D(pool_size= (2,2), padding= 'same'),\n",
    "        \n",
    "        layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPool2D(pool_size= (2,2), padding= 'same'),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(num_classes_hood, activation='softmax')\n",
    "\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e09f8e1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def transferLearn_model():\n",
    "    '''Uses pretrained model as a base and build dense layers on top of it'''\n",
    "    \n",
    "    augmentation = Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomZoom(0.1),\n",
    "        layers.RandomTranslation(0.2, 0.2),\n",
    "        layers.RandomRotation(0.1)\n",
    "    ])\n",
    "    \n",
    "    base_model= resnet50.ResNet50(weights='imagenet', input_shape=X_train_door[0,:,:].shape, include_top=False,\\\n",
    "                           pooling= None)\n",
    "    \n",
    "    base_model.trainable=False\n",
    "    \n",
    "    model= Sequential([\n",
    "        layers.Input(X_train_door[0,:,:].shape),\n",
    "        augmentation,\n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(2048, activation=\"relu\"),\n",
    "        layers.Dense(1024, activation=\"relu\"),\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        #layers.Dropout(0.2),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(num_classes_hood, activation=\"softmax\"),\n",
    "\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0979baeb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model= base_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ee597e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot the model architecture\n",
    "plot_model(model, show_shapes= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6327a152",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compile_model(model, lr, epochs=None):\n",
    "    '''return a compiled model suited for the task'''\n",
    "    \n",
    "    #opt= Adam(learning_rate= lr, decay= lr/epochs)\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate= lr), loss= 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb10931",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train_augment(model, batch_size, epochs, patience, train_flow=None):\n",
    "    \"\"\"This function returns the fitted model and its train history\"\"\"\n",
    "    \n",
    "    # apply model regularization techniques\n",
    "    MODEL= 'model_base_door'\n",
    "    modelCheckpoint= ModelCheckpoint(\"{}.h5\".format(MODEL), monitor=\"val_loss\", verbose=0,\\\n",
    "                                               save_best_only=True)\n",
    "    earlyStop= EarlyStopping(monitor='val_loss', mode='min', restore_best_weights=True, patience=patience)\n",
    "    lreducer= ReduceLROnPlateau(monitor=\"val_loss\",factor=0.1,patience= patience, verbose=2\n",
    "                            ,mode=\"min\", min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "    \n",
    "    # fit the model\n",
    "    history = model.fit(X_train_hood,\n",
    "                        y_train_hood,\n",
    "                      batch_size=batch_size,\n",
    "                      steps_per_epoch= int(len(X_train_hood)/batch_size),\n",
    "                      epochs = epochs,\n",
    "                      callbacks = [modelCheckpoint, earlyStop, lreducer],\n",
    "                      validation_data = (X_val_hood, y_val_hood))\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c7ae6c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train the base model\n",
    "model= base_model()\n",
    "compiled_model= compile_model(model, lr= 1e-3, epochs= 50)\n",
    "model, history= train_augment(compiled_model, batch_size= 64, epochs= 50, patience= 10)\n",
    "model.save('./baseModel_hood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0673d4e2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train the transfer learning model\n",
    "model= transferLearn_model()\n",
    "compiled_model= compile_model(model, lr= 1e-4, epochs= 50)\n",
    "model, history= train_augment(compiled_model, batch_size= 32, epochs= 50, patience= 10)\n",
    "model.save('./transferLearn_model_hood')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846bf641",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Alternative Way for more Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8457bd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_hood= X_train_hood / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581a1e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# apply augmentation to batches of images and store them in memory\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center = False,\n",
    "    featurewise_std_normalization = False,\n",
    "    rotation_range = 10,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    horizontal_flip = True,\n",
    "    zoom_range = (0.8, 1.2)\n",
    ")\n",
    "\n",
    "train_datagen.fit(X_train_hood)\n",
    "\n",
    "train_flow = train_datagen.flow(X_train_hood, shuffle= False, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7aa5f8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show augmented images alongside original ones\n",
    "for i, (raw_img, aug_img) in enumerate(zip(X_train_hood, train_flow)):\n",
    "    _,(ax1, ax2)= plt.subplots(1,2, figsize=(6,3))\n",
    "    ax1.imshow(raw_img)\n",
    "    ax2.imshow(aug_img[0])\n",
    "    ax1.axis('off')\n",
    "    ax2.axis('off')\n",
    "    plt.show();\n",
    "    \n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8efa05",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bd551e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9138f43e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot the model training history\n",
    "def plot_history(history):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "    ax[0].set_title('loss')\n",
    "    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "    ax[1].set_title('accuracy')\n",
    "    ax[1].plot(history.epoch, history.history[\"accuracy\"], label=\"Train acc\")\n",
    "    ax[1].plot(history.epoch, history.history[\"val_accuracy\"], label=\"Validation acc\")\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f452cbb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1876d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# prepare testing data\n",
    "split_hood= 'data/split_hood2/'\n",
    "X_test_hood, y_test_hood= create_dataset(split_hood + 'test')\n",
    "X_test_hood, y_test_hood= shuffle(X_test_hood, y_test_hood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb43fbbc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# scale pixels of test data according to the trained model\n",
    "X_test_hood= resnet50.preprocess_input(X_test_hood).astype(float)\n",
    "y_test_hood= y_test_hood.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63938516",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_hood.shape, y_test_hood.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2de2a2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_classes_hood= len(np.unique(y_test_hood, return_counts=False))\n",
    "num_classes_hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdff05f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# put the labels in categorical vectors\n",
    "y_test_hood= to_categorical(y_test_hood, num_classes= num_classes_hood)\n",
    "y_test_hood.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ee6e6d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "model_path= './transferLearn_model_hood'\n",
    "loaded_model= tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0ac4c4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# the test accuracy is low since we specified the test data to be only 5% of the total amount, we wanted to save \n",
    "# most of data for training, we could have split data as (0.6, 0.2, 0.2) to have enough for testing\n",
    "metrics= loaded_model.evaluate(X_test_hood, y_test_hood, return_dict=True)\n",
    "metrics['loss'], metrics['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b604b32c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred_hood= loaded_model.predict(X_test_hood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2516ca16",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# the rmetrics are bad for classes 3,4 due to lack of sample data\n",
    "print(classification_report(y_test_hood, y_pred_hood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cee2dd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show the confusion matrix, focus on how many true positives and true negatives are captured compared to false \n",
    "# positives and false negatives for each class -- again we could have saved more samples for testing\n",
    "\n",
    "labels= [str(i) for i in range(0,6)]\n",
    "conf_mat= {}\n",
    "for label in range(len(labels)):\n",
    "    #print(label)\n",
    "    y_test_label= y_test_hood[:,label]\n",
    "    #print(y_test_label)\n",
    "    y_pred_label= y_pred_hood[:, label]\n",
    "    conf_mat[labels[label]]= confusion_matrix(y_pred= y_pred_label, y_true= y_test_label)\n",
    "for label, matrix in conf_mat.items():\n",
    "    print('confusion matrix for label {}:'.format(label))\n",
    "    print(matrix)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875b90da",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show testing images from each class with corresponding true and predicted labels\n",
    "for f in os.listdir(split_hood + '/test'):\n",
    "    subfolders= os.path.join(split_hood, 'test',f)\n",
    "    if os.path.isdir(subfolders):\n",
    "        files = [file for file in os.listdir(subfolders) if os.path.isfile(os.path.join(subfolders, file))]\n",
    "        # Select random images\n",
    "        random_images = random.sample(files, min(5, len(files)))\n",
    "        print(f'taking images from {subfolders}'); print()\n",
    "        for img in random_images:\n",
    "            #print(f'loading image from {os.path.join(subfolders, img)}')\n",
    "            loaded_img = image.load_img(os.path.join(subfolders, img), target_size=(90, 90))\n",
    "            test_img= cv2.imread(os.path.join(subfolders, img), cv2.COLOR_BGR2RGB)\n",
    "            test_img= cv2.resize(test_img, (160,160))\n",
    "            img_array = image.img_to_array(test_img)\n",
    "\n",
    "            img_batch = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "            img_preprocessed = preprocess_input(img_batch)\n",
    "\n",
    "            prediction = loaded_model.predict(img_preprocessed)\n",
    "            prediction= np.argmax(prediction, axis=1)\n",
    "            plt.imshow(loaded_img)\n",
    "            plt.show()\n",
    "            print(f'predicted label: {prediction[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c81294b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Draft (Extra Coding) – Approach2: Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3754fd68",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f79b98a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_hood= df.groupby(['perspective_score_hood'])['filename'].agg(list)\\\n",
    ".reset_index().rename(columns={'filename':'filename_hood'})\n",
    "df_hood.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475bfed1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_door= df.groupby(['perspective_score_backdoor_left'])['filename'].agg(list)\\\n",
    ".reset_index().rename(columns={'filename':'filename_door'})\n",
    "df_hood.shape, df_door.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6d8a90",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_combined= pd.concat([df_hood, df_door], axis=1)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cd6e42",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_combined[df_combined['perspective_score_backdoor_left'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e94f17",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_combined.dropna(inplace=True)\n",
    "df_combined.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d74244e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1802aad9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def move_files(files, min_count):\n",
    "    # Ensure max_count is within the bounds of the list\n",
    "    min_count = min(min_count, len(files))\n",
    "    \n",
    "    # Move files to a new column up to max_count\n",
    "    return files[min_count:]\n",
    "\n",
    "min_count = 4\n",
    "\n",
    "# Apply the move_files function to the 'filename' list column\n",
    "df_filtered= df_combined.copy()\n",
    "df_filtered['files_filtered'] = df_filtered['filename'].apply(lambda files: \\\n",
    "                                    move_files(files, min_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c985c01",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007f8c79",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "base_dir= 'data/original_data/imgs'\n",
    "\n",
    "def create_features_labels(base_dir):\n",
    "    images=[]\n",
    "    labels_hood=[]\n",
    "    labels_door=[]\n",
    "\n",
    "    IMG_WIDTH=160\n",
    "    IMG_HEIGHT=160\n",
    "    for img in df.filename:\n",
    "        img_path= os.path.join(base_dir, img)\n",
    "        image= cv2.imread(img_path, cv2.COLOR_BGR2RGB)\n",
    "        image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH))\n",
    "        images.append(image)\n",
    "    for label_hood, label_door in zip(df.perspective_score_hood.values, df.perspective_score_backdoor_left.values):\n",
    "        labels_hood.append(label_hood)\n",
    "        labels_door.append(label_door)\n",
    "    \n",
    "    return np.array(images), np.array(labels_hood), np.array(labels_door) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc66f06e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "features, labels_hood, labels_door = create_features_labels(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a582a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "features.shape, labels_hood.shape, labels_door.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ffecee",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,8))\n",
    "sns.countplot(labels_hood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a73ba5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,8))\n",
    "sns.countplot(labels_door)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5c31a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_hood, y_test_hood, y_train_door, y_test_door= train_test_split(features, labels_hood, \\\n",
    "                                                    labels_door, test_size= 0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d1b590",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train_hood.shape, y_test_hood.shape, y_train_door.shape, y_test_door.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcac1ac5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train_hood, y_val_hood, y_train_door, y_val_door = train_test_split(X_train, y_train_hood,\\\n",
    "                                        y_train_door, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7dea70",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, y_train_hood.shape, y_val_hood.shape, y_train_door.shape, y_val_door.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc0708",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "over = SMOTE(sampling_strategy= 'auto')\n",
    "under= RandomUnderSampler(sampling_strategy= 'majority')\n",
    "steps= [('o', over), ('u', under)]\n",
    "pipeline= Pipeline(steps= steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a479cbf5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4535220",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_train_door.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb59e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_classes= len(pd.Series(y_train_hood).unique())\n",
    "y_train_cat= to_categorical(y_train_hood, num_classes= num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307581f3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_classes_door= len(pd.Series(y_train_door).unique())\n",
    "#num_classes_door\n",
    "y_train_door_cat= to_categorical(y_train_door, num_classes= num_classes_door)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ae7e38",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241bd6c1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_balance, y_train_hood_balance= under.fit_resample(X_train.reshape(len(X_train),160*160*3)\\\n",
    "                        ,y_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d4b712",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_balance, y_train_door_balance= under.fit_resample(X_train.reshape(len(X_train),160*160*3)\\\n",
    "                        ,y_train_door_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b782076",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train_balance.shape, y_train_hood_balance.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7bb218",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_balance.shape, y_train_door_balance.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5aa7bb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Ref: https://github.com/keras-team/keras/issues/13081\n",
    "# we dont need it for integer labels\n",
    "\n",
    "def to_categorical(y,num_classes):\n",
    "    ''' Converts a class vector of dtype float or int to binary class matrix.\n",
    "    \n",
    "    E.g. for use with categorical_crossentropy.\n",
    "    \n",
    "    # Arguments\n",
    "        y: class vector to be converted into a matrix\n",
    "            (floar or int).\n",
    "        num_classes: total number of classes\n",
    "            (total number of unique entries of y)\n",
    "    # Returns\n",
    "        A binary matrix representation of the input. The classes axis\n",
    "        is placed last. \n",
    "    '''\n",
    "    uniques = np.unique(y)\n",
    "    Binary_Matrix = np.zeros([y.shape[0],num_classes])\n",
    "\n",
    "    \n",
    "    for idx_uniques,value_uniques in enumerate(uniques):\n",
    "        for idx_class,value_class in enumerate(y):\n",
    "            if value_uniques == value_class:\n",
    "                Binary_Matrix[idx_class,idx_uniques]=1\n",
    "                \n",
    "    return Binary_Matrix\n",
    "\n",
    "# Or for string labels\n",
    "#pd.get_dummies(y_train, dtype= float).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34817cc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    '''instanciate and return the CNN architecture of your choice with less than 150,000 params'''\n",
    "    # hood modelling\n",
    "    input_hood= layers.Input(X_train_hood[0,:,:].shape) \n",
    "    x_hood= layers.Conv2D(16, (3,3), activation='relu', padding='same')(input_hood)\n",
    "    x_hood= layers.MaxPool2D(2,2)(x_hood)\n",
    "\n",
    "    x_hood= layers.Conv2D(32, (3,3), activation='relu', padding='same')(x_hood)\n",
    "    x_hood= layers.MaxPool2D(2,2)(x_hood)\n",
    "\n",
    "    x_hood= layers.Conv2D(64, (2,2), activation='relu', padding='same')(x_hood)\n",
    "    x_hood= layers.MaxPool2D(2,2)(x_hood)\n",
    "\n",
    "    x_hood= layers.Flatten()(x_hood)\n",
    "    x_hood= Model(inputs= input_hood, outputs= x_hood)\n",
    "        \n",
    "    # door modelling\n",
    "    input_door= layers.Input(X_train_door[0,:,:].shape) \n",
    "    x_door= layers.Conv2D(16, (3,3), activation='relu', padding='same')(input_door)\n",
    "    x_door= layers.MaxPool2D(2,2)(x_door)\n",
    "\n",
    "    x_door= layers.Conv2D(32, (3,3), activation='relu', padding='same')(x_door)\n",
    "    x_door= layers.MaxPool2D(2,2)(x_door)\n",
    "\n",
    "    x_door= layers.Conv2D(64, (2,2), activation='relu', padding='same')(x_door)\n",
    "    x_door= layers.MaxPool2D(2,2)(x_door)\n",
    "\n",
    "    x_door= layers.Flatten()(x_door)\n",
    "    x_door= Model(inputs= input_door, outputs= x_door)\n",
    "    \n",
    "    merge= layers.concatenate([x_hood.output, x_door.output])\n",
    "    \n",
    "    last= layers.Dense(64, activation='relu')(merge)\n",
    "    \n",
    "    out_hood= layers.Dense(num_classes_hood, activation='softmax')(last)\n",
    "    out_door= layers.Dense(num_classes_door, activation='softmax')(last)\n",
    "    \n",
    "    # combine the two models\n",
    "    model = Model(inputs= [x_hood.input, x_door.input], outputs= [out_hood, out_door])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65db3069",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epochs= 2\n",
    "batch_size= 32\n",
    "lr= 1e-3\n",
    "\n",
    "def compile_model(model):\n",
    "    '''return a compiled model suited for the CIFAR-10 task'''\n",
    "    losses= {\n",
    "        'categorical_hood':'categorical_crossentropy',\n",
    "        'categorical_door':'categorical_crossentropy'\n",
    "    }\n",
    "    \n",
    "    lossWeights= {\n",
    "        'categorical_hood':1.0,\n",
    "        'categorical_door':1.0\n",
    "    }\n",
    "    \n",
    "    opt= Adam(learning_rate= lr, decay= lr/epochs)\n",
    "    \n",
    "    model.compile(optimizer=opt, loss= losses, loss_weights= lossWeights, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fa4a22",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "compiled_model= compile_model(model) \n",
    "compiled_model.fit(x= [X_train_hood, X_train_door], y= [y_train_hood, y_train_door], \\\n",
    "                   validation_data=([X_val_hood, X_val_door], [y_val_hood, y_val_door]),\\\n",
    "                    epochs= epochs, batch_size= batch_size, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
