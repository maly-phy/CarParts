{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b612fc52",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69add9de",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil, glob, random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db285000",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62db1b8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv('./data/car_imgs_4000.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c25fe9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd28a1",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['perspective_score_hood']= round(df.perspective_score_hood, 2)\n",
    "df['perspective_score_backdoor_left']= round(df.perspective_score_backdoor_left, 2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c4d22f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157260e6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show the class imbalance in the data\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, figsize=(30,10))\n",
    "sns.countplot((df.perspective_score_hood.values * 100).astype(int), ax= ax1)\n",
    "plt.ylabel('hood_count');\n",
    "\n",
    "sns.countplot((df.perspective_score_backdoor_left.values * 100).astype(int), ax= ax2)\n",
    "plt.ylabel('door_count');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d71f8f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#df.perspective_score_backdoor_left.value_counts(normalize=False).sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7f7a7c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show 5 samples of the croped images\n",
    "src_dir= 'data/croped_imgs2/'\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    f= os.listdir(src_dir)[i]\n",
    "    img_path= os.path.join(src_dir, f)\n",
    "    #print(img_path)\n",
    "    img= image.load_img(img_path)\n",
    "    img= img.resize((90,90))\n",
    "    img= image.img_to_array(img)/255.\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis('off')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71717453",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show the classes with majority sample\n",
    "\n",
    "#np.where(df.perspective_score_hood.value_counts(normalize=True) > 0.050)\n",
    "#df[df.groupby('perspective_score_hood')['perspective_score_hood'].transform('size') > 0.50]\n",
    "count= df.perspective_score_hood.value_counts(normalize=True)\n",
    "df[df.perspective_score_hood.map(count >0.06)]['perspective_score_hood'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30478bf8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mergeing classes into 5 to have enough samples per class for training\n",
    "#classes ranges for modelling:\n",
    "# 0 = 0.0 - 0.20\n",
    "# 1 = 0.21 - 0.40\n",
    "# 2 = 0.41 - 0.60\n",
    "# 3 = 0.61 - 0.80\n",
    "# 4 = 0.81 - 0.93\n",
    "\n",
    "src_dir= './data/croped_imgs/'\n",
    "save_dir= './data/merged_hood/'\n",
    "class_0 = []\n",
    "#missing= [i for i in set(df.perspective_score_hood.values) if str(i) not in os.listdir(save_dir)]\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "for image in os.listdir(src_dir):\n",
    "    for i in np.arange(0.91,0.92,0.01):\n",
    "        i = round(i,2)\n",
    "        for v, f in zip(df.perspective_score_hood.values, df.filename):\n",
    "            if v == i and f in os.path.join(src_dir, image):\n",
    "                #print(v)\n",
    "                class_0.append([f, v])\n",
    "                sub_dir= os.path.join(save_dir, str(5))\n",
    "                os.makedirs(sub_dir, exist_ok= True)\n",
    "                #print('*'*50)\n",
    "                shutil.move(os.path.join(src_dir, f), os.path.join(sub_dir, f))\n",
    "                print(f'moved from {os.path.join(src_dir, f)} to { os.path.join(sub_dir, f)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e1d9fb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# count the images in a subfolder\n",
    "count = 0\n",
    "save_dir= 'data/split_hood2/test'\n",
    "# Iterate directory\n",
    "for path in os.listdir(save_dir):\n",
    "    for file in os.listdir(os.path.join(save_dir,path)):\n",
    "    # check if current path is a file\n",
    "        if os.path.isfile(os.path.join(save_dir, path, file)):\n",
    "            count += 1\n",
    "print('File count:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884bfbb5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# count images in each subfolder\n",
    "for dir,subdir,files in os.walk('data/merged_hood'):\n",
    "    print(np.sort([dir, str(len(files))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d07bf2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sepecify images in each class up to max_number and remove the rest to a folder for the sake of class balancing\n",
    "\n",
    "# Set the path to the directory containing labeled subdirectories\n",
    "base_dir = 'data/merged_hood'\n",
    "\n",
    "# Specify the desired subdirectory labels\n",
    "desired_labels = ['0.00', '0.90', '0.91']\n",
    "\n",
    "# Set the destination directory\n",
    "dest_dir = 'data/residue_hood/'\n",
    "if not os.path.exists(dest_dir):\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "# Specify the maximum allowed count\n",
    "max_count = 400\n",
    "\n",
    "# Loop through each subdirectory, count images, and move if count exceeds max_count\n",
    "for subdir_label in os.listdir(base_dir):\n",
    "    if subdir_label == str(4):\n",
    "        subdir_path = os.path.join(base_dir, subdir_label)\n",
    "        # Get a list of files in the subdirectory\n",
    "        files = [file for file in os.listdir(subdir_path) if os.path.isfile(os.path.join(subdir_path, file))]\n",
    "        \n",
    "        # Count the number of images in the subdirectory\n",
    "        count = len(files)\n",
    "        \n",
    "        # Print or process the count\n",
    "        print(f\"Number of images in {subdir_label}: {count}\")\n",
    "        \n",
    "        # Move images if count exceeds max_count\n",
    "        if count > max_count:\n",
    "            # Select the first (count - max_count) images to move\n",
    "            images_to_move = files[:count - max_count]\n",
    "            \n",
    "            # Move selected images to the destination directory\n",
    "            for image in images_to_move:\n",
    "                source_path = os.path.join(subdir_path, image)\n",
    "                sub_dest_dir = os.path.join(dest_dir, subdir_label)\n",
    "                os.makedirs(sub_dest_dir, exist_ok= True)\n",
    "                shutil.move(source_path, os.path.join(sub_dest_dir, str(image)))\n",
    "                print(f\"Moved {image} to {dest_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff8ec46",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(os.listdir('data/merged_hood/4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd28dbd7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Crop Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfb321c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9644dce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# crop images with a pretrained Yolo-v8 model\n",
    "# We trained Yolo with 500 samples and validated and tested with 500 each. We ran the model for 50 epochs on TPU\n",
    "# Colab – the loss in the detection box was roughly 1.6 – we could have trained the model for 100 epochs with\n",
    "# more samples (e.g 1000) for better croping accuracy\n",
    "\n",
    "custom_model = YOLO('best.pt')\n",
    "base_dir= 'data/original_data/imgs/'\n",
    "\n",
    "for image in os.listdir(base_dir):\n",
    "    img_path= os.path.join(base_dir, image)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    img= cv2.resize(img, (160, 160), interpolation= cv2.INTER_AREA)\n",
    "    results = custom_model(img)\n",
    "    for n, box in enumerate(results[0].boxes.xywhn):\n",
    "        h, w = img.shape[:2]\n",
    "        x1, y1, x2, y2 = box.numpy()\n",
    "        x_center, y_center = int(float(x1) * w), int(float(y1) * h)\n",
    "        box_width, box_height = int(float(x2) * w), int(float(y2) * h)\n",
    "\n",
    "        x_min = int(x_center - (box_width / 2))\n",
    "        y_min = int(y_center - (box_height / 2))\n",
    "        crop_img= img[y_min:y_min+int(box_height), x_min:x_min+int(box_width)]\n",
    "\n",
    "        save_path= f'data/croped_imgs/'\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path, exist_ok= True)\n",
    "        cv2.imwrite(save_path + f\"{image}\", crop_img)\n",
    "        print(f'crop image {img_path} to {os.path.join(save_path,image)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef61d8a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(os.listdir('data/croped_imgs2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b9fd79",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Split Data for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee541f77",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import vgg16, resnet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813668f7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_hood= 'data/merged_hood/'\n",
    "#data_door= 'data/balanced_door_croped/'\n",
    "\n",
    "split_hood= 'data/split_hood2/'\n",
    "#split_door= 'data/split_door/'\n",
    "\n",
    "#splitfolders.ratio(data_hood, split_hood, seed=1337, ratio= (0.70, 0.25, 0.05))\n",
    "#splitfolders.ratio(data_door, split_door, seed=1337, ratio= (0.70, 0.25, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726bc93f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create features and corresponding labels\n",
    "\n",
    "def create_dataset(img_folder):\n",
    "    features=[]\n",
    "    labels=[]\n",
    "    IMG_WIDTH=160\n",
    "    IMG_HEIGHT=160\n",
    "    for label in os.listdir(img_folder):\n",
    "        image_path= os.path.join(img_folder,label)\n",
    "        for img in os.listdir(image_path):\n",
    "            image= cv2.imread(os.path.join(image_path, img), cv2.COLOR_BGR2RGB)\n",
    "            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH))\n",
    "            features.append(image)\n",
    "            labels.append(label)\n",
    "    features, labels = shuffle(features, labels)\n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf966a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_hood, y_train_hood= create_dataset(split_hood + 'train')\n",
    "#X_train_door, y_train_door= create_dataset(split_door + 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ed103",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_val_hood, y_val_hood= create_dataset(split_hood + 'val')\n",
    "#X_val_door, y_val_door= create_dataset(split_door + 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d9b37",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_classes_hood= len(np.unique(y_train_hood, return_counts=False))\n",
    "#num_classes_door= len(np.unique(y_train_door, return_counts=False))\n",
    "print(num_classes_hood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d40a8a4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# manual split of data (or by using splitfolders library as above)\n",
    "\n",
    "# train_size_hood= int(len(features_hood) * 0.80)\n",
    "\n",
    "# X_train_hood= features_hood[:train_size_hood]\n",
    "# y_train_hood= labels_hood[:train_size_hood]\n",
    "# X_val_hood= features_hood[train_size_hood:]\n",
    "# y_val_hood= labels_hood[train_size_hood:]\n",
    "\n",
    "# train_size_door= int(len(features_door) * 0.80)\n",
    "\n",
    "# X_train_door= features_door[:train_size_door]\n",
    "# y_train_door= labels_door[:train_size_door]\n",
    "# X_val_door= features_door[train_size_door:]\n",
    "# y_val_door= labels_door[train_size_door:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3486058",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check the shape of features and labels\n",
    "X_train_hood.shape, y_train_hood.shape, X_val_hood.shape, y_val_hood.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c9b851",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#X_train_door.shape, y_train_door.shape, X_val_door.shape, y_val_door.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a73ea4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# categorical encoding for integer labels\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_hood= to_categorical(y_train_hood, num_classes= num_classes_hood)\n",
    "y_val_hood= to_categorical(y_val_hood, num_classes= num_classes_hood)\n",
    "\n",
    "#y_train_door= to_categorical(y_train_door, num_classes= num_classes_door)\n",
    "#y_val_door= to_categorical(y_val_door, num_classes= num_classes_door)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf83163a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# For base Modelling or implement it in the model architecture as Rescaling layer\n",
    "# X_train_hood= X_train_hood/255.\n",
    "# X_val_hood= X_val_hood/255.\n",
    "\n",
    "# X_train_door= X_train_door/255.\n",
    "# X_val_door= X_val_door/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64911787",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# For Transfer Learning Modelling\n",
    "X_train_hood= resnet50.preprocess_input(X_train_hood).astype(float)\n",
    "X_val_hood= resnet50.preprocess_input(X_val_hood).astype(float)\n",
    "\n",
    "#X_train_door= vgg16.preprocess_input(X_train_door).astype(float)\n",
    "#X_val_door= vgg16.preprocess_input(X_val_door).astype(float)\n",
    "\n",
    "y_train_hood= y_train_hood.astype(float)\n",
    "y_val_hood= y_val_hood.astype(float)\n",
    "\n",
    "#y_train_door= y_train_door.astype(float)\n",
    "#y_val_door= y_val_door.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccaa504",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_door[0,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d44a6e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    '''instanciate and return the CNN architecture with augmenting and rescaling layers'''\n",
    "    \n",
    "    augmentation = Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomZoom(0.1),\n",
    "        layers.RandomTranslation(0.2, 0.2),\n",
    "        layers.RandomRotation(0.1)\n",
    "    ])\n",
    "    \n",
    "    model= Sequential([\n",
    "        layers.Input(X_train_hood[0,:,:].shape),\n",
    "        layers.Rescaling(scale= 1./255.),\n",
    "        augmentation,\n",
    "        layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPool2D(pool_size= (2,2), padding= 'same'),\n",
    "        \n",
    "        layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPool2D(pool_size= (2,2), padding= 'same'),\n",
    "\n",
    "        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPool2D(pool_size= (2,2), padding= 'same'),\n",
    "        \n",
    "        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPool2D(pool_size= (2,2), padding= 'same'),\n",
    "        \n",
    "        layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPool2D(pool_size= (2,2), padding= 'same'),\n",
    "        \n",
    "        layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPool2D(pool_size= (2,2), padding= 'same'),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(num_classes_hood, activation='softmax')\n",
    "\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e09f8e1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def transferLearn_model():\n",
    "    '''Uses pretrained model as a base and build dense layers on top of it'''\n",
    "    \n",
    "    augmentation = Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomZoom(0.1),\n",
    "        layers.RandomTranslation(0.2, 0.2),\n",
    "        layers.RandomRotation(0.1)\n",
    "    ])\n",
    "    \n",
    "    base_model= resnet50.ResNet50(weights='imagenet', input_shape=(160,160,3), include_top=False,\\\n",
    "                           pooling= None)\n",
    "    \n",
    "    base_model.trainable=False\n",
    "    \n",
    "    model= Sequential([\n",
    "        layers.Input((160,160,3)),\n",
    "        augmentation,\n",
    "        base_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(2048, activation=\"relu\"),\n",
    "        layers.Dense(1024, activation=\"relu\"),\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        #layers.Dropout(0.2),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(num_classes_hood, activation=\"softmax\"),\n",
    "\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0979baeb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model= base_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ee597e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot the model architecture\n",
    "model= transferLearn_model()\n",
    "model.summary()\n",
    "#plot_model(model, show_shapes= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6327a152",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compile_model(model, lr, epochs=None):\n",
    "    '''return a compiled model suited for the task'''\n",
    "    \n",
    "    #opt= Adam(learning_rate= lr, decay= lr/epochs)\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate= lr), loss= 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb10931",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train_augment(model, batch_size, epochs, patience, train_flow=None):\n",
    "    \"\"\"This function returns the fitted model and its train history\"\"\"\n",
    "    \n",
    "    # apply model regularization techniques\n",
    "    MODEL= 'model_base_door'\n",
    "    modelCheckpoint= ModelCheckpoint(\"{}.h5\".format(MODEL), monitor=\"val_loss\", verbose=0,\\\n",
    "                                               save_best_only=True)\n",
    "    earlyStop= EarlyStopping(monitor='val_loss', mode='min', restore_best_weights=True, patience=patience)\n",
    "    lreducer= ReduceLROnPlateau(monitor=\"val_loss\",factor=0.1,patience= patience, verbose=2\n",
    "                            ,mode=\"min\", min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "    \n",
    "    # fit the model\n",
    "    history = model.fit(X_train_hood,\n",
    "                        y_train_hood,\n",
    "                      batch_size=batch_size,\n",
    "                      steps_per_epoch= int(len(X_train_hood)/batch_size),\n",
    "                      epochs = epochs,\n",
    "                      callbacks = [modelCheckpoint, earlyStop, lreducer],\n",
    "                      validation_data = (X_val_hood, y_val_hood))\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c7ae6c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train the base model\n",
    "model= base_model()\n",
    "compiled_model= compile_model(model, lr= 1e-3, epochs= 50)\n",
    "model, history= train_augment(compiled_model, batch_size= 64, epochs= 50, patience= 10)\n",
    "model.save('./baseModel_hood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0673d4e2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train the transfer learning model\n",
    "model= transferLearn_model()\n",
    "compiled_model= compile_model(model, lr= 1e-4, epochs= 50)\n",
    "model, history= train_augment(compiled_model, batch_size= 32, epochs= 50, patience= 10)\n",
    "model.save('./transferLearn_model_hood')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846bf641",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Alternative Way for more Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8457bd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_hood= X_train_hood / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581a1e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# apply augmentation to batches of images and store them in memory\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center = False,\n",
    "    featurewise_std_normalization = False,\n",
    "    rotation_range = 10,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    horizontal_flip = True,\n",
    "    zoom_range = (0.8, 1.2)\n",
    ")\n",
    "\n",
    "train_datagen.fit(X_train_hood)\n",
    "\n",
    "train_flow = train_datagen.flow(X_train_hood, shuffle= False, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7aa5f8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show augmented images alongside original ones\n",
    "for i, (raw_img, aug_img) in enumerate(zip(X_train_hood, train_flow)):\n",
    "    _,(ax1, ax2)= plt.subplots(1,2, figsize=(6,3))\n",
    "    ax1.imshow(raw_img)\n",
    "    ax2.imshow(aug_img[0])\n",
    "    ax1.axis('off')\n",
    "    ax2.axis('off')\n",
    "    ax1.set_title('true_img')\n",
    "    ax2.set_title('aug_img')\n",
    "    plt.show();\n",
    "    \n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8efa05",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bd551e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9138f43e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot the model training history\n",
    "def plot_history(history):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "    ax[0].set_title('loss')\n",
    "    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "    ax[1].set_title('accuracy')\n",
    "    ax[1].plot(history.epoch, history.history[\"accuracy\"], label=\"Train acc\")\n",
    "    ax[1].plot(history.epoch, history.history[\"val_accuracy\"], label=\"Validation acc\")\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f452cbb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1876d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# prepare testing data\n",
    "split_hood= 'data/split_hood2/'\n",
    "X_test_hood, y_test_hood= create_dataset(split_hood + 'test')\n",
    "#X_test_hood, y_test_hood= shuffle(X_test_hood, y_test_hood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb43fbbc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# scale pixels of test data according to the trained model\n",
    "X_test_hood= resnet50.preprocess_input(X_test_hood).astype(float)\n",
    "y_test_hood= y_test_hood.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63938516",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_hood.shape, y_test_hood.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2de2a2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_classes_hood= len(np.unique(y_test_hood, return_counts=False))\n",
    "num_classes_hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdff05f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# put the labels in categorical vectors\n",
    "y_test_hood= to_categorical(y_test_hood, num_classes= num_classes_hood)\n",
    "y_test_hood.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ee6e6d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "model_path= './transferLearn_model_hood'\n",
    "loaded_model= tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0ac4c4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# the test accuracy is low since we specified the test data to be only 5% of the total amount, we wanted to save \n",
    "# most of data for training, we could have split data as (0.6, 0.2, 0.2) to have enough for testing\n",
    "metrics= loaded_model.evaluate(X_test_hood, y_test_hood, return_dict=True)\n",
    "metrics['loss'], metrics['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b604b32c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred_hood= loaded_model.predict(X_test_hood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2516ca16",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# the rmetrics are bad for classes 3,4 due to lack of sample data\n",
    "print(classification_report(y_test_hood, y_pred_hood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cee2dd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show the confusion matrix, focus on how many true positives and true negatives are captured compared to false \n",
    "# positives and false negatives for each class -- again we could have saved more samples for testing\n",
    "\n",
    "labels= [str(i) for i in range(0,6)]\n",
    "conf_mat= {}\n",
    "for label in range(len(labels)):\n",
    "    #print(label)\n",
    "    y_test_label= y_test_hood[:,label]\n",
    "    #print(y_test_label)\n",
    "    y_pred_label= y_pred_hood[:, label]\n",
    "    conf_mat[labels[label]]= confusion_matrix(y_pred= y_pred_label, y_true= y_test_label)\n",
    "for label, matrix in conf_mat.items():\n",
    "    print('confusion matrix for label {}:'.format(label))\n",
    "    print(matrix)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe5f9be",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_hood= np.round(y_pred_hood).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc73d27",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cm= multilabel_confusion_matrix(y_pred_hood, y_test_hood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5c9b79",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#label= [i for i in labels]\n",
    "cm= multilabel_confusion_matrix(y_pred_hood, y_test_hood)\n",
    "for i, confusion_matrix in enumerate(cm):\n",
    "    #print(confusion_matrix)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix)\n",
    "    disp.plot()\n",
    "    disp.ax_.set_title('{}'.format(labels[i]))\n",
    "\n",
    "    #disp.plot(include_values=True, cmap=\"viridis\", ax=None, xticks_rotation=\"vertical\")\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bfa124",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show testing images from each class with corresponding true and predicted labels\n",
    "for f in os.listdir(split_hood + '/test'):\n",
    "    subfolders= os.path.join(split_hood, 'test',f)\n",
    "    if os.path.isdir(subfolders):\n",
    "        files = [file for file in os.listdir(subfolders) if os.path.isfile(os.path.join(subfolders, file))]\n",
    "        # Select random images\n",
    "        random_images = random.sample(files, min(5, len(files)))\n",
    "        print(f'taking images from {subfolders}'); print()\n",
    "        for i,img in enumerate(random_images):\n",
    "            #print(f'loading image from {os.path.join(subfolders, img)}')\n",
    "            loaded_img = image.load_img(os.path.join(subfolders, img), target_size=(60, 60))\n",
    "            test_img= cv2.imread(os.path.join(subfolders, img), cv2.COLOR_BGR2RGB)\n",
    "            test_img= cv2.resize(test_img, (160,160))\n",
    "            img_array = image.img_to_array(test_img)\n",
    "\n",
    "            img_batch = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "            img_preprocessed = resnet50.preprocess_input(img_batch)\n",
    "\n",
    "            prediction = loaded_model.predict(img_preprocessed)\n",
    "            prediction= np.argmax(prediction, axis=1)\n",
    "            plt.subplot(1,5,i+1)\n",
    "            #plt.subplots_adjust(top=0.88)\n",
    "            plt.imshow(loaded_img)\n",
    "            plt.title(f' predicted label: {prediction[0]}', fontsize=8)\n",
    "            plt.axis('off')\n",
    "        plt.suptitle(f'taking images from class {f}', ha='center', va='bottom', fontsize=12, y=0.65)\n",
    "        plt.tight_layout()\n",
    "        plt.show();\n",
    "            #print(f'predicted label: {prediction[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c81294b",
   "metadata": {},
   "source": [
    "## Approach2: Combined Model – One Input and Multitarget Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6436ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb92cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted loss function to balance the data – can only be applied to training data after split\n",
    "# class_counts= df['filename'].value_counts()\n",
    "# class_weights= len(class_counts)/class_counts\n",
    "# resample_df= df.sample(n= class_counts.max()*len(class_counts), weights= df['filename'].map(class_weights), replace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007f8c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_labels(base_dir):\n",
    "    images=[]\n",
    "    labels_hood=[]\n",
    "    labels_door=[]\n",
    "\n",
    "    IMG_WIDTH=160\n",
    "    IMG_HEIGHT=160\n",
    "    for img in df.filename:\n",
    "        img_path= os.path.join(base_dir, img)\n",
    "        image= cv2.imread(img_path, cv2.COLOR_BGR2RGB)\n",
    "        image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH))\n",
    "        images.append(image)\n",
    "    for label_hood, label_door in zip(df.perspective_score_hood.values, df.perspective_score_backdoor_left.values):\n",
    "        labels_hood.append(label_hood)\n",
    "        labels_door.append(label_door)\n",
    "    \n",
    "    #images, labels_hood, label_door= shuffle(images, label_hood, label_door)\n",
    "    return np.array(images), np.array(labels_hood), np.array(labels_door) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a685321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('data/original_data/imgs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc66f06e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_dir= 'data/original_data/imgs'\n",
    "X_train, y_train_hood, y_train_door = create_features_labels(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a582a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train_hood.shape, y_train_door.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5c31a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_hood, y_test_hood, y_train_door, y_test_door= train_test_split(X_train, y_train_hood, \\\n",
    "                                                    y_train_door, test_size= 0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d1b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train_hood.shape, y_test_hood.shape, y_train_door.shape, y_test_door.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcac1ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train_hood, y_val_hood, y_train_door, y_val_door = train_test_split(X_train, y_train_hood,\\\n",
    "                                        y_train_door, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7dea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, y_train_hood.shape, y_val_hood.shape, y_train_door.shape, y_val_door.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_door"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc0708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be applied only to one target, unfortunately these methods dont accept multi-target variable\n",
    "\n",
    "# over = SMOTE(sampling_strategy= 'minority')\n",
    "# under= RandomUnderSampler(sampling_strategy= 'majority')\n",
    "# steps= [('o', over), ('u', under)]\n",
    "# pipeline= Pipeline(steps= steps)\n",
    "\n",
    "# X_train_balance, y_train_hood_balance= under.fit_resample(X_train.reshape(len(X_train),160*160*3)\\\n",
    "#                         ,y_train_cat)\n",
    "\n",
    "# X_train_balance, y_train_door_balance= under.fit_resample(X_train.reshape(len(X_train),160*160*3)\\\n",
    "#                         ,y_train_door_cat)\n",
    "\n",
    "# X_train_balance.shape, y_train_hood_balance.reshape(-1,1).shape\n",
    "\n",
    "# X_train_balance.shape, y_train_door_balance.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e5efc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(x):\n",
    "    x= layers.RandomFlip(\"horizontal\")(x)\n",
    "    x= layers.RandomZoom(0.1)(x)\n",
    "    x= layers.RandomTranslation(0.2, 0.2)(x)\n",
    "    x= layers.RandomRotation(0.1)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34817cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    '''instanciate and return the CNN architecture'''\n",
    "    \n",
    "    input_layer= layers.Input(shape= (160,160,3))\n",
    "    x= layers.Rescaling(scale= 1/255.)(input_layer)\n",
    "    x= augment(x)\n",
    "    x= layers.Conv2D(16, (3,3), activation='relu', padding='same')(x)\n",
    "    x= layers.MaxPool2D(2,2)(x)\n",
    "\n",
    "    x= layers.Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
    "    x= layers.MaxPool2D(2,2)(x)\n",
    "\n",
    "    x= layers.Conv2D(64, (2,2), activation='relu', padding='same')(x)\n",
    "    x= layers.MaxPool2D(2,2)(x)\n",
    "\n",
    "    x= layers.Flatten()(x)\n",
    "    x= layers.Dense(64, activation= 'relu')(x)\n",
    "    x= layers.Dense(32, activation= 'relu')(x)\n",
    "    #x= layers.Dropout(0.2)(x)\n",
    "    out_hood= layers.Dense(1, activation= 'sigmoid', name= 'out_hood')(x)\n",
    "    out_door= layers.Dense(1, activation= 'sigmoid', name= 'out_door')(x)\n",
    "    model= Model(inputs= input_layer, outputs= [out_hood, out_door])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0635f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd0d00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(initialize_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80770b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    model.compile(loss= ['binary_crossentropy', 'binary_crossentropy'], optimizer= 'adam', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fa4a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result for activation= sigmoid, loss= binary_crossentropy\n",
    "model= initialize_model()\n",
    "compiled_model= compile_model(model) \n",
    "compiled_model.fit(x= X_train, y= [y_train_hood, y_train_door], \\\n",
    "                   validation_data=(X_val, [y_val_hood, y_val_door]),\\\n",
    "                    epochs= 30, batch_size= 32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a113fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result for activation= linear, loss= mse\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(loss= ['mse', 'mse'], optimizer= 'adam', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "model= initialize_model()\n",
    "compiled_model= compile_model(model) \n",
    "compiled_model.fit(x= X_train, y= [y_train_hood, y_train_door], \\\n",
    "                   validation_data=(X_val, [y_val_hood, y_val_door]),\\\n",
    "                    epochs= 30, batch_size= 32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_hood= model.layers[-2].output\n",
    "out_hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d5c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/66715975/class-weights-in-cnn\n",
    "hood_class_weight= class_weight.compute_class_weight(class_weight= 'balanced',\\\n",
    "                        classes= sorted(np.unique(y_train_hood)), y= y_train_hood)\n",
    "door_class_weight= class_weight.compute_class_weight(class_weight= 'balanced',\\\n",
    "                        classes= sorted(np.unique(y_train_door)),y= y_train_door)\n",
    "hood_class_weight= {i:hood_class_weight[i] for i, label in enumerate(sorted(np.unique(y_train_hood)))}\n",
    "door_class_weight= {i:door_class_weight[i] for i, label in enumerate(sorted(np.unique(y_train_door)))}\n",
    "\n",
    "class_weights={\n",
    "    'out_hood':hood_class_weight,\n",
    "    'out_door':door_class_weight\n",
    "}\n",
    "#hood_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92f75ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/keras-team/keras/issues/11735\n",
    "def class_loss(class_weight):\n",
    "  \"\"\"Returns a loss function for a specific class weight tensor\n",
    "  \n",
    "  Params:\n",
    "    class_weight: 1-D constant tensor of class weights\n",
    "    \n",
    "  Returns:\n",
    "    A loss function where each loss is scaled according to the observed class\"\"\"\n",
    "  def loss(y_obs, y_pred):\n",
    "    y_obs = tf.dtypes.cast(y_obs, tf.int32)\n",
    "    hothot = tf.one_hot(tf.reshape(y_obs, [-1]), depth=class_weight.shape[0])\n",
    "    weight = tf.math.multiply(class_weight, hothot)\n",
    "    weight = tf.reduce_sum(weight, axis=-1)\n",
    "    losses = tf.compat.v1.losses.sparse_softmax_cross_entropy(labels=y_obs,\n",
    "                                                              logits=y_pred,\n",
    "                                                              weights=weight)\n",
    "    return losses\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297b51b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tried to balance the classes with compute_class_weight from sklearn, but the class_weight in the fit() method\n",
    "# accepts only dict and neither list of dict or dict of dict for balancing multitargets simultaneously\n",
    "def compile_model(model):\n",
    "    \n",
    "    model.compile(loss= {k: class_loss(v) for k,v in class_weights.items()}, optimizer= 'adam', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a56bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9986130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model.save('regres_linear_act')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157492fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation results for model with activation= linear, loss= mse\n",
    "# plot the model training history\n",
    "\n",
    "def plot_history(history):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "    ax[0].set_title('loss')\n",
    "    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "    ax[1].set_title('mae')\n",
    "    ax[1].plot(history.epoch, history.history[\"dense_41_mae\"], label=\"Train mae\")\n",
    "    ax[1].plot(history.epoch, history.history[\"val_dense_41_mae\"], label=\"Validation mae\")\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f87283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one can increase the batch size to reduce the stochastic behaviour of the loss,\n",
    "#however the model converged at end of training\n",
    "plot_history(compiled_model.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b43f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled= X_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dea6eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_hood, y_pred_door= compiled_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d08187",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_hood.shape, y_pred_door.shape, y_test_hood.shape, y_test_door.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3026047",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_hood= mean_absolute_error(y_test_hood, y_pred_hood)\n",
    "mae_door= mean_absolute_error(y_test_door, y_pred_door)\n",
    "print('MAE hood error: %.3f' % mae_hood)\n",
    "print('MAE door error: %.3f' % mae_door)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a41a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_hood_error= mean_squared_error(y_test_hood, y_pred_hood)\n",
    "mse_door_error= mean_squared_error(y_test_door, y_pred_door)\n",
    "print('mse hood score: %.3f' % mse_hood_error)\n",
    "print('mse door score: %.3f' % mse_door_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f172f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics= compiled_model.evaluate(X_test_scaled, y_test_hood, return_dict=True)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1abc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_door= compiled_model.evaluate(X_test_scaled, y_test_door, return_dict=True)\n",
    "metrics_door"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7fc862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path= './regres_linear_act'\n",
    "#loaded_model= tf.keras.models.load_model(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
